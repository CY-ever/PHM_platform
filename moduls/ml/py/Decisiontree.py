# -*- coding: utf-8 -*-
"""DecisionTree.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MRw4PiOhkj6nEzu0jVc9LCOUKoDc3Zhy
"""

import numpy as np
import pandas as pd
# from sklearn.externals import joblib
import joblib
from sklearn import tree
from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
# from keras.utils.np_utils import to_categorical
from tensorflow.keras.utils import to_categorical


# from sklearn.externals import joblib


class Param:
    criterion = 'gini'
    # criterion = 'mse'
    splitter = 'best'
    max_depth = None
    min_samples_split = 2
    min_samples_leaf = 1
    min_weight_fraction_leaf = 0.0
    max_features = None
    random_state = None
    max_leaf_nodes = None
    min_impurity_decrease = 0.0
    min_impurity_split = None
    class_weight = None
    ccp_alpha = 0.0


class Option:
    sample_weight = None
    check_input = True
    X_idx_sorted = None


def DT_Model(x_train, y_train, params, typ="DecisionTreeClassifier"):  # Main program

    # 参数准备
    param_use = Param
    param_use.max_depth = params[0]
    param_use.max_leaf_nodes = params[1]
    param_use = param_process(param_use)

    model = model_select(param_use, typ)

    # x_train, x_val, y_train, y_val = create_dataSet(path)
    # trainParam = get_trainParam(x_train, y_train, Option)
    model = train_model(x_train, y_train, model)
    # savePath = save_model(model, savePath)
    return model


def param_process(Param):  # Parameter type conversion
    if Param.max_depth == 0:
        Param.max_depth = None
    if Param.max_features == 0:
        Param.max_features = None
    if Param.random_state == 0:
        Param.random_state = None
    if Param.max_leaf_nodes == 0:
        Param.max_leaf_nodes = None
    if Param.min_impurity_split == 0:
        Param.min_impurity_split = None
    if Param.class_weight == 0:
        Param.class_weight = None
    else:
        Param.class_weight = 'balanced'
    return Param


def option_process(Option):  # Parameter type conversion
    Option.sample_weight = None
    if Option.X_idx_sorted == 0:
        Option.X_idx_sorted = None
    return Option


def model_select(Param, typ):  # Build a model based on the parameters passed by the user

    if "DecisionTreeClassifier" == typ:
        model = tree.DecisionTreeClassifier(splitter=Param.splitter,
                                            max_depth=Param.max_depth, min_samples_split=Param.min_samples_split,
                                            min_samples_leaf=Param.min_samples_leaf
                                            , min_weight_fraction_leaf=Param.min_weight_fraction_leaf,
                                            max_features=Param.max_features, random_state=Param.random_state,
                                            max_leaf_nodes=Param.max_leaf_nodes
                                            , min_impurity_decrease=Param.min_impurity_decrease,
                                            # min_impurity_split=Param.min_impurity_split,
                                            class_weight=Param.class_weight, ccp_alpha=Param.ccp_alpha)
        return model

    elif "DecisionTreeRegressor" == typ:
        model = tree.DecisionTreeRegressor(splitter=Param.splitter,
                                           max_depth=Param.max_depth, min_samples_split=Param.min_samples_split,
                                           min_samples_leaf=Param.min_samples_leaf
                                           , min_weight_fraction_leaf=Param.min_weight_fraction_leaf,
                                           max_features=Param.max_features, random_state=Param.random_state,
                                           max_leaf_nodes=Param.max_leaf_nodes
                                           , min_impurity_decrease=Param.min_impurity_decrease,
                                           # min_impurity_split=Param.min_impurity_split,
                                           ccp_alpha=Param.ccp_alpha)
        return model


# Process various data used for training and put them into the
# dictionary for calling
def get_trainParam(Xtrain, Ytrain, Option):
    trainParam = {'data': Xtrain, 'label': Ytrain, 'sample_weight': Option.sample_weight,
                  'check_input': Option.check_input, 'X_idx_sorted': Option.X_idx_sorted}
    return trainParam


def train_model(x_train, y_train, model):  # Train and return to the model
    model = model.fit(x_train, y_train, sample_weight=None,
                      check_input=True)
    return model


def get_score(x_train, x_test, y_train, y_test, params, rul_pre=False):

    if not rul_pre:
        rf = DT_Model(x_train, y_train, params, typ="DecisionTreeClassifier")
        pre = rf.predict(x_test)
        # 正确率
        score = rf.score(x_test, y_test)

    else:
        rf = DT_Model(x_train, y_train, params, typ="DecisionTreeRegressor")
        pre = np.array(rf.predict(x_test).tolist())
        y_test_use = y_test.ravel()
        score = r2_score(y_test_use, pre)  # 准确率

    # Error = 1 - score
    return pre, score


def create_dataSet(path):  # Load data set
    list = []
    path1 = path[0]
    path2 = path[1]
    feature = 'feature'
    for i in range(0, 576):  # Add a name to each column of features :column='feature'+i
        column = feature + str(i)
        list.append(column)
    df = pd.read_csv(path1, names=list, header=0)  # Take the first 110000 rows and all columns of data

    DataSet = df[:11000].iloc[:, 0:576]  # Read the label of the training set
    df1 = pd.read_csv(path2)  # Rename the features of the training set
    df1.columns = ['label']  # Rename the features of the training set
    LabelSet = df1[:11000].iloc[:, :]  # Take the labels of the first 110,000 lines
    # 将label转化为独热编码
    Labels = to_categorical(LabelSet, num_classes=None)
    X_train, X_val, Y_train, Y_val = train_test_split(DataSet, Labels, test_size=0.3,
                                                      random_state=42)  # split 30% of the data set into a validation set
    x_train = X_train.values
    x_val = X_val.values

    y_train = Y_train
    y_val = Y_val
    return x_train, x_val, y_train, y_val


def fun_predict(savePath, path):  # Predict the input
    model = load_model(savePath)
    x_val = create_dataSet(path)[1]
    array_list = model.predict(x_val).tolist()
    length = len(array_list)
    prediction = []
    for i in range(0, length):
        label = array_list[i]
        for j in range(0, len(label)):
            if label[j] != 0:
                prediction.append(j + 1)

    return prediction


def fun_score(savePath, path):  # Evaluate the model, the higher the score, the better the model
    model = load_model(savePath)
    x_train, x_val, y_train, y_val = create_dataSet(path)
    score = model.score(x_val, y_val)
    return score


def save_model(model, savePath):  # Save model
    joblib.dump(model, savePath)
    return savePath


def load_model(savePath):  # Load the model
    model = joblib.load(savePath)
    return model
